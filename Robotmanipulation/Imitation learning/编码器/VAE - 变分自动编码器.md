#### AE架构如下
![[Pasted image 20250530114334.png]]
#### VAE猜想
![[Pasted image 20250530120549.png]]
* Target:只需要Decoder的部分，随机生成一个feature，就能得到一张新图片
#### AE缺陷
* 对于一个训练好的AE，输入某个图片，就只会将其编码为某个确定的feature，输入特定的code就只会输出特定的图片，如果这个feature来源自没见过的图片，那么生成的图片质量也不会好
![[Pasted image 20250530120758.png]]
* 假设我们训练好的AE将“新月”图片encode成code=1（这里假设code只有1维），将其decode能得到“新月”的图片；将“满月”encode成code=10，同样将其decode能得到“满月”图片。这时候如果我们给AE一个code=5，我们希望是能得到“半月”的图片，但由于之前训练时并没有将“半月”的图片编码，或者将一张非月亮的图片编码为5，那么我们就不太可能得到“半月”的图片。因此AE多用于数据的压缩和恢复，用于数据生成时效果并不理想。

#### 解决问题
* 把`数值编码feature`更改为`分布`
* 将`新月`从特征编码1变为特征为1区间$\mu=1$  的正态分布 
* 将`满月`从特征编码10变为特征为10区间$\mu=10$的正态分布
* 求最大似然估计，求特征编码为5区间$\mu=5$的正态分布区间
![[Pasted image 20250530124846.png]]
### #VAE架构
![[Pasted image 20250530125141.png]]
* 如上图所示，VAE与AE整体结构类似，不同的地方在于AE的Encoder直接输出code，而VAE的Encoder输出的是若干个正态分布的均值(μ1,μ2...μnμ1,μ2...μn)和标准差(σ1,σ2...σnσ1,σ2...σn)，然后从每个正态分布N(μ1,σ21),N(μ2,σ22)...N(μn,σ2n)N(μ1,σ12),N(μ2,σ22)...N(μn,σn2)采样得到编码code(Z1,Z2...Zn)(Z1,Z2...Zn)，再将code送入Decoder进行解码

VAE的loss函数
* 1. 为了让输出和输入尽可能像，所以要让输出和输入的差距尽可能小，此部分用MSELoss来计算，即最小化MSELoss
* 2. 训练过程当中，如果仅使输入和输出的误差尽可能小，那么随着不断训练，会使得σσ趋近于0，这样就使得VAE越来越像AE，丢失了随机性。对数据产生了过拟合，编码的噪声也会消失，导致无法生成未见过的数据(为了解决这个问题，我们要对μμ和σσ加以约束，使其构成的正态分布尽可能像标准正态分布，具体做法是计算N(μ,σ2)N(μ,σ2)与N(0,1)N(0,1)之间的KL散度，即最小化下式)
$$ \mathrm{KL}(\mathcal{N}(\mu, \sigma^2) \,\|\, \mathcal{N}(0, 1)) = \frac{1}{2} \left( -\log \sigma^2 + \mu^2 + \sigma^2 - 1 \right $$