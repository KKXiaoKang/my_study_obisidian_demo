{
  "main": {
    "id": "6578f350d3521b16",
    "type": "split",
    "children": [
      {
        "id": "fedc471460dd44c5",
        "type": "tabs",
        "children": [
          {
            "id": "08475499fd671a9f",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "Robotmanipulation/Imitation learning/rewACT - 将MLP结构的reward model融合在ACT训练当中.md",
                "mode": "source",
                "source": false
              },
              "icon": "lucide-file",
              "title": "rewACT - 将MLP结构的reward model融合在ACT训练当中"
            }
          },
          {
            "id": "361336513b7ab1dd",
            "type": "leaf",
            "state": {
              "type": "image",
              "state": {
                "file": "RobotRL/Hil-Serl/IMG/Pasted image 20250703140939.png"
              },
              "icon": "lucide-image",
              "title": "Pasted image 20250703140939"
            }
          },
          {
            "id": "3ca7bf858dfd3dde",
            "type": "leaf",
            "state": {
              "type": "image",
              "state": {
                "file": "RobotRL/Hil-Serl/IMG/Pasted image 20250807183013.png"
              },
              "icon": "lucide-image",
              "title": "Pasted image 20250807183013"
            }
          },
          {
            "id": "80bdf80209d26b03",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "RobotRL/Hil-Serl/☆ - SAC recipe experiments log 对比 baseline PPO.md",
                "mode": "source",
                "source": false
              },
              "icon": "lucide-file",
              "title": "☆ - SAC recipe experiments log 对比 baseline PPO"
            }
          },
          {
            "id": "218fdcb872d484f5",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "RobotRL/stable-baselines3 框架解析/common.base_class.BaseAlgorithm.md",
                "mode": "source",
                "source": false
              },
              "icon": "lucide-file",
              "title": "common.base_class.BaseAlgorithm"
            }
          }
        ]
      }
    ],
    "direction": "vertical"
  },
  "left": {
    "id": "c070085dce14b810",
    "type": "split",
    "children": [
      {
        "id": "78376e57fe44cd3a",
        "type": "tabs",
        "children": [
          {
            "id": "86eaf77f5f480c18",
            "type": "leaf",
            "state": {
              "type": "file-explorer",
              "state": {
                "sortOrder": "alphabetical",
                "autoReveal": true
              },
              "icon": "lucide-folder-closed",
              "title": "文件列表"
            }
          },
          {
            "id": "8f565fa2097fe86e",
            "type": "leaf",
            "state": {
              "type": "search",
              "state": {
                "query": "tensorb",
                "matchingCase": false,
                "explainSearch": false,
                "collapseAll": false,
                "extraContext": false,
                "sortOrder": "alphabetical"
              },
              "icon": "lucide-search",
              "title": "搜索"
            }
          },
          {
            "id": "38cba28462e40663",
            "type": "leaf",
            "state": {
              "type": "bookmarks",
              "state": {},
              "icon": "lucide-bookmark",
              "title": "书签"
            }
          }
        ]
      }
    ],
    "direction": "horizontal",
    "width": 457.5
  },
  "right": {
    "id": "f68e4ca4c1083328",
    "type": "split",
    "children": [
      {
        "id": "ba2e240981bd450d",
        "type": "tabs",
        "children": [
          {
            "id": "4b7130247660a444",
            "type": "leaf",
            "state": {
              "type": "backlink",
              "state": {
                "file": "三维重建/MLP - 多层感知机.md",
                "collapseAll": false,
                "extraContext": false,
                "sortOrder": "alphabetical",
                "showSearch": false,
                "searchQuery": "",
                "backlinkCollapsed": false,
                "unlinkedCollapsed": true
              },
              "icon": "links-coming-in",
              "title": "MLP - 多层感知机 的反向链接列表"
            }
          },
          {
            "id": "f74aaba4c359f528",
            "type": "leaf",
            "state": {
              "type": "outgoing-link",
              "state": {
                "file": "欢迎.md",
                "linksCollapsed": false,
                "unlinkedCollapsed": true
              },
              "icon": "links-going-out",
              "title": "欢迎 的出链列表"
            }
          },
          {
            "id": "62af8b43aa7c5cf7",
            "type": "leaf",
            "state": {
              "type": "tag",
              "state": {
                "sortOrder": "frequency",
                "useHierarchy": true,
                "showSearch": false,
                "searchQuery": ""
              },
              "icon": "lucide-tags",
              "title": "标签"
            }
          },
          {
            "id": "4a97499e98ebb30c",
            "type": "leaf",
            "state": {
              "type": "outline",
              "state": {
                "file": "RobotVision/三维重建/AGS-Mesh 高斯结合Mesh.md",
                "followCursor": false,
                "showSearch": false,
                "searchQuery": ""
              },
              "icon": "lucide-list",
              "title": "AGS-Mesh 高斯结合Mesh 的大纲"
            }
          },
          {
            "id": "476eac75ac6d0b04",
            "type": "leaf",
            "state": {
              "type": "git-view",
              "state": {},
              "icon": "git-pull-request",
              "title": "Source Control"
            }
          }
        ],
        "currentTab": 4
      }
    ],
    "direction": "horizontal",
    "width": 300,
    "collapsed": true
  },
  "left-ribbon": {
    "hiddenItems": {
      "switcher:打开快速切换": false,
      "graph:查看关系图谱": false,
      "canvas:新建白板": false,
      "daily-notes:打开/创建今天的日记": false,
      "templates:插入模板": false,
      "command-palette:打开命令面板": false,
      "obsidian-git:Open Git source control": false
    }
  },
  "active": "08475499fd671a9f",
  "lastOpenFiles": [
    "Robotmanipulation/Imitation learning/IMG/Pasted image 20250813165725.png",
    "Robotmanipulation/Imitation learning/IMG/reward_visualization_train.mp4",
    "Robotmanipulation/Imitation learning/IMG/0_A_rewACT_仿真演示测试_原子策略跑_reward拿obs去推测reward.mp4",
    "Robotmanipulation/Imitation learning/※ ACT -  Transformer CVAE动作生成器.md",
    "Robotmanipulation/Imitation learning/rewACT - 将MLP结构的reward model融合在ACT训练当中.md",
    "Robot工具/关于Lerobot 中 torchcodec 视频编码Tensor工具库难装的问题.md",
    "Robot工具/IMG/img_v3_02p3_1aca9b99-bb1c-4a8f-9b30-acdb223f032g.jpg",
    "Robot工具/IMG",
    "RobotRL/stable-baselines3 框架解析/common.base_class.BaseAlgorithm.md",
    "RobotRL/stable-baselines3 框架解析/common.off_policy_algorithm.OffPolicyAlgorithm.md",
    "RobotRL/☆  基于视觉的Sim2real的抓取manipulation RL/Sim-to-Real Reinforcement Learning for Vision-Based Dexterous Manipulation on Humanoids.md",
    "RobotRL/Hil-Serl/☆ - SAC recipe experiments log 对比 baseline PPO.md",
    "RobotRL/Hil-Serl/IMG/Pasted image 20250807183013.png",
    "RobotRL/Hil-Serl/IMG/Pasted image 20250703140939.png",
    "RobotRL/Hil-Serl/IMG/Pasted image 20250807182949.png",
    "RobotRL/Hil-Serl/IMG/Pasted image 20250807182959.png",
    "RobotRL/Hil-Serl/IMG/Pasted image 20250807183025.png",
    "RobotRL/Hil-Serl/IMG/Pasted image 20250807191020.png",
    "RobotRL/Hil-Serl/IMG/Pasted image 20250807191522.png",
    "RobotRL/Hil-Serl/IMG/Pasted image 20250807191908.png",
    "RobotRL/Hil-Serl/IMG/Pasted image 20250807193505.png",
    "RobotRL/Hil-Serl/lerobot - Hil-Serl pipeline说明.md",
    "RobotRL/Reward设计/manipulation reward 设计.md",
    "RobotRL/Reward设计/default joint reward - 设计思路.md",
    "Robotmanipulation/Imitation learning/编码器/MLP - 多层感知机.md",
    "RobotRL/SAC/SAC - `RunningMeanStd` 观测归一化工具.md",
    "RobotRL/SAC/SAC - load or save model.md",
    "RobotRL/SAC/SAC - train and learn.md",
    "RobotRL/SAC/SAC - (actor-Critic 架构).md",
    "Robotmanipulation/Imitation learning/Transformer/04 - Transformer - Decoder结构.md",
    "Robotmanipulation/Imitation learning/Transformer/03 - Transformer - Encoder结构.md",
    "Robotmanipulation/Imitation learning/Transformer/02 - Transformer - Self-Attention（自注意力机制）.md",
    "Robotmanipulation/Imitation learning/Transformer/Attention Is All You Need -  Transformer 开山之作 - pipeline.md",
    "Robotmanipulation/Imitation learning/Transformer/01 - Transformer - Transformer 输入.md",
    "RobotRL/☆  基于视觉的Sim2real的抓取manipulation RL/IMG/Sim-to-Real Reinforcement Learning for Vision-Based Dexterous Manipulation on Humanoids.pdf",
    "RobotRL/☆  基于视觉的Sim2real的抓取manipulation RL/IMG",
    "RobotRL/☆  基于视觉的Sim2real的抓取manipulation RL",
    "RobotRL/未命名.md",
    "Robotmanipulation/Imitation learning/Transformer/IMG",
    "Robotmanipulation/Imitation learning/Transformer",
    "RobotRL/0801 - KuavoEnv Debug log.md",
    "RobotRL/0801 - DEBUG LOG - Learner.md",
    "RobotRL/0801 - DEBUG LOG - Actor.md",
    "RobotRL/Q-learning DQN/贝尔曼方程 - Bellman Optimality Equation.md",
    "RobotRL/Reward设计",
    "Robot工具/BugLog - bt2pro手柄机器人初始后乱走/IMG",
    "Robot工具/未命名.canvas",
    "未命名.canvas"
  ]
}