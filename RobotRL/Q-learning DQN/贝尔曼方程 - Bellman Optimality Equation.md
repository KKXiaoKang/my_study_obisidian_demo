* 动态规划方程构建方式
### 状态值函数 $V(s)$
![[Pasted image 20250707151726.png]]
$$V_{\pi}(s) = \sum_a \pi(a | s) \cdot q_{\pi}(s, a)$$
* 其中$q_{\pi}(s, a)$ 是指该状态$s$下选取动作$a$的Q值
* $\pi(a | s)$ 则是该状态$s$下选取$a$动作的可能性
* 计算 ： 而$\sum_{a}$ 就是将上述的该状态$s$下所有动作的Q值求一个加权平均值, 权重来源于$\pi(a | s)$ 

> $V(s)$ 是对未来所有可能性的一种`综合期望`。 假设 “你在某个十字路口（状态s）的前景如何（V值）”，取决于“你可能选择的各条道路（动作a）的前景（Q值）”以及“你选择走每条路的概率（策略π）”


### 动作值函数 $Q(s, a)$ 
![[Pasted image 20250707152859.png]]
$$q_{\pi}(s, a) = \sum_{s', r} p(s', r|s, a)\cdot[r+\gamma v_{\pi}(s') ]$$
* 其中 $r$ 为当前状态从 $s$ 转移到 $s'$ 当中获取的奖励